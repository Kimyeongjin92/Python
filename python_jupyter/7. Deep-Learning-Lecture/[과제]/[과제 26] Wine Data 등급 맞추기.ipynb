{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-encoding을 써야할거여~ 등급맞추기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/coalastudy/data-science-lv1/blob/master/week6/wine.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/wine.csv',header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:11]\n",
    "Y = dataset[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 17:30:35.928571  4920 deprecation_wrapper.py:119] From C:\\Users\\709-000\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0813 17:30:35.929571  4920 deprecation_wrapper.py:119] From C:\\Users\\709-000\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0813 17:30:35.931571  4920 deprecation_wrapper.py:119] From C:\\Users\\709-000\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0813 17:30:35.971576  4920 deprecation_wrapper.py:119] From C:\\Users\\709-000\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=11, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss',\n",
    "                               verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.50304\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.50304\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500,\n",
    "                   verbose=0, callbacks=[early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제등급:6.000,예상등급:5.522\n",
      "실제등급:6.000,예상등급:6.546\n",
      "실제등급:6.000,예상등급:5.608\n",
      "실제등급:5.000,예상등급:4.805\n",
      "실제등급:8.000,예상등급:6.230\n",
      "실제등급:5.000,예상등급:5.811\n",
      "실제등급:6.000,예상등급:6.345\n",
      "실제등급:6.000,예상등급:5.439\n",
      "실제등급:6.000,예상등급:6.164\n",
      "실제등급:6.000,예상등급:6.237\n"
     ]
    }
   ],
   "source": [
    "# 모델의 학습이 어느 정도 되었는지 확인하기 위해 \n",
    "# 예측 값과 실제 값을 비교하는 부분을 추가한다.\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제등급:{:.3f},예상등급:{:.3f}\".format(label,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c= \"blue\",markersize=3)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
